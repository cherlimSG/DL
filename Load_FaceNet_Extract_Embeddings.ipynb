{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cher Eng Lim - Load_FaceNet_Extract_Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jT0LsKvu8qY"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pry6uKut6GlG"
      },
      "source": [
        "#Load Pre-Trained FaceNet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnTU2U458VrT",
        "outputId": "a520c6ee-2106-4d74-a8ca-e7ef34a3c454"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-SRJEuW6Kbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c87cb9d-7bcd-423e-834c-5c0176e5b0eb"
      },
      "source": [
        "model_dir = '/content/drive/MyDrive/L12/'\n",
        "os.chdir(model_dir)\n",
        "\n",
        "# load the model\n",
        "model = load_model('Cher Eng Lim - facenet_keras.h5')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uus-_fzy7cMI"
      },
      "source": [
        "##Activity 1: Information of the pre-trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGzD60VY7qIE"
      },
      "source": [
        "- Number of layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKx3uis26lWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1cf983-28b4-48f4-8b66-ce5e3aac407a"
      },
      "source": [
        "print(\"Number of layer = \", len(model.layers))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of layer =  426\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0l0x-e7uE1"
      },
      "source": [
        "- Input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0KXARnI7hUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e36bf60-47c8-4318-b4ff-e25eb58a427a"
      },
      "source": [
        "print(\"Input = \", model.input_shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input =  (None, 160, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAWlP9697ysf"
      },
      "source": [
        "The information tells you that we need to feed images of size $160\\times 160$ pixels. Images are colored ones (RGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx6UYwJO8AjE"
      },
      "source": [
        "- Ouput"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhu93Uhd8Coh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d282572-dbb6-4dd4-90b2-1c4e60296a9a"
      },
      "source": [
        "print(\"Output = \", model.output_shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output =  (None, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vOGelw98LuS"
      },
      "source": [
        "After feeding an image to the model, the output of the model is an array of length $128$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwjTvwkv9HE8"
      },
      "source": [
        "#Load a face and feed it the the pre-trained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtu3-01Y9NTf"
      },
      "source": [
        "Change directory to the one containing some faces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMrSl_hJ9N4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85310a72-27da-49fd-c9a1-326c2a1bf999"
      },
      "source": [
        "face_dir = '/content/drive/MyDrive/Cher Eng Lim - faces.zip (Unzipped Files)/faces'\n",
        "os.chdir(face_dir)\n",
        "%ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "face01.PNG  face03_02.PNG  face04.PNG  face06.PNG  face08.PNG     face09.PNG\n",
            "face02.PNG  face03.PNG     face05.PNG  face07.PNG  face09_02.PNG  face10.PNG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Pncd97-gBy"
      },
      "source": [
        "We will use `Image` module of `Pillow`, Python Imaging Library, to handle images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyVu77zP-ujX"
      },
      "source": [
        "import PIL.Image as Image"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyedpBT-_AZw"
      },
      "source": [
        "Load `face10.PNG` and print out the size of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNI6NxOv_HAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f4e84c-9c6f-44b7-9818-529c5e5e5e97"
      },
      "source": [
        "# load the image and convert to RGB\n",
        "face10 = Image.open('face10.PNG').convert(\"RGB\")\n",
        "\n",
        "# convert it to numpy array\n",
        "face10_np = np.asarray(face10)\n",
        "\n",
        "# print the size\n",
        "print(\"Size of the face:\", face10_np.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the face: (409, 291, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0ntWm6LAAJv"
      },
      "source": [
        "The size of the face is not $160\\times 160$. Therefore, we need to resize it (using `Image` module) before converting it numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niKXcv55AbXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6371f617-8326-4d7a-90b8-4f1ecbd36ab4"
      },
      "source": [
        "# load the image and convert to RGB\n",
        "face10 = Image.open('face10.PNG').convert(\"RGB\")\n",
        "\n",
        "#resize\n",
        "required_size = (160,160)\n",
        "face10_resized = face10.resize(required_size)\n",
        "\n",
        "# convert it to numpy array\n",
        "face10_np = np.asarray(face10_resized)\n",
        "\n",
        "# print the size\n",
        "print(\"Size of the face:\", face10_np.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the face: (160, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDfYFq7qA0-J"
      },
      "source": [
        "Before feeding it to the model we need to do normalize the face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wbavSXDA4Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38315316-ff93-47f4-c774-ea4fd06c6383"
      },
      "source": [
        "# just to make sure the pixels are of float32 type\n",
        "face10_np = face10_np.astype('float32')\n",
        "\n",
        "# standardize pixel values across channels\n",
        "mean, std = face10_np.mean(), face10_np.std()\n",
        "print(\"Mean = \", mean)\n",
        "print(\"STD = \", std)\n",
        "\n",
        "face10_np = (face10_np - mean) / std"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean =  125.16738\n",
            "STD =  50.166664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pflhht_jDZnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d446ac6f-9266-49d4-d19e-fb2902f0ee8e"
      },
      "source": [
        "# transform the face into (1, 160, 160, 3)\n",
        "face10_np_expanded = np.expand_dims(face10_np, axis = 0)\n",
        "print(\"Size after expansion: \", face10_np_expanded.shape)\n",
        "\n",
        "# getting the embeddings of the face\n",
        "face10_embedding = model.predict(face10_np_expanded)\n",
        "\n",
        "print(\"\\nType of the embedding: \", type(face10_embedding))\n",
        "print(\"Size of the embedding: \", face10_embedding.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size after expansion:  (1, 160, 160, 3)\n",
            "\n",
            "Type of the embedding:  <class 'numpy.ndarray'>\n",
            "Size of the embedding:  (1, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY3rQqxsEpGf"
      },
      "source": [
        "We have sucessfully covert a face into an array of $128$ numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVPww1BKGySD"
      },
      "source": [
        "##Activity 2: Write a function to convert a numpy array of size $160\\times 160\\times 3$ into an array of length $128$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifrzIomxG-RW"
      },
      "source": [
        "def convert_to_embedding(face, model):\n",
        "\n",
        "  face = face.astype('float32')\n",
        "  \n",
        "  mean, std = face.mean(), face.std()\n",
        "  face = (face - mean) / std\n",
        "\n",
        "  face_expanded = np.expand_dims(face, axis=0)\n",
        "\n",
        "  face_embedding = model.predict(face_expanded)\n",
        "\n",
        "  return face_embedding"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7KTdKmCIplP"
      },
      "source": [
        "Call the function to calculate the embedding of `face10.PNG` and calculate its L2-norm\n",
        "\n",
        "Note: \n",
        "\n",
        "For a vector of $n$ elements, $\\boldsymbol{x}=[x_1,\\ x_2, \\ \\cdots,\\ x_n]^T$ then its L2-norm is\n",
        "\n",
        "$|\\boldsymbol{x}|_2=\\sqrt{x_1^2+x_2^2+\\cdots+x_n^2}$\n",
        "\n",
        "We can use [`np.np.linalg.norm()`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html) to calculate this norm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C1Wl84XH3iZ"
      },
      "source": [
        "face10 = Image.open('face10.PNG').convert(\"RGB\")\n",
        "face10_resized = face10.resize(required_size)\n",
        "face10_np = np.asarray(face10_resized)\n",
        "\n",
        "face10_embedding = convert_to_embedding(face10_np, model)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0aE4ucUIBSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e14644bc-004c-4222-d871-8c750eac7d82"
      },
      "source": [
        "print(\"L2-norm of the embedding = \", np.linalg.norm(face10_embedding))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-norm of the embedding =  10.799945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79bhbCARJ5Q4"
      },
      "source": [
        "#Compare embeddings of different and similar faces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRrsFa-7KPSf"
      },
      "source": [
        "##Activity 3\n",
        "- Calculate the embeedings of `face02.PNG`\n",
        "\n",
        "- Calculate the embeedings of `face03.PNG` and `face03_02.PNG`\n",
        "\n",
        "- Calculate the L2-norm of\n",
        "\n",
        "  - The difference of embeedings of `face02.PNG` and `face03.PNG`.\n",
        "  - The difference of embeedings of `face03.PNG` and `face03_02.PNG`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi8StGC0KM8q"
      },
      "source": [
        "face02 = Image.open('face02.PNG').convert(\"RGB\")\n",
        "face02_resized = face02.resize(required_size)\n",
        "face02_np = np.asarray(face02_resized)\n",
        "\n",
        "face02_embedding = convert_to_embedding(face02_np, model)\n",
        "\n",
        "#face02_embedding = ........................"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"L2-norm of the embedding = \", np.linalg.norm(face02_embedding))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssEvo4KGBpCD",
        "outputId": "fb94b72b-2524-42d4-9e51-6ed14df4294e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-norm of the embedding =  9.374028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNyKRLT2KwPK"
      },
      "source": [
        "face03 = Image.open('face03.PNG').convert(\"RGB\")\n",
        "face03_resized = face03.resize(required_size)\n",
        "face03_np = np.asarray(face03_resized)\n",
        "\n",
        "face03_embedding = convert_to_embedding(face03_np, model)\n",
        "\n",
        "#face03_embedding = ........................\n",
        "\n",
        "face03_02 = Image.open('face03_02.PNG').convert(\"RGB\")\n",
        "face03_02_resized = face03_02.resize(required_size)\n",
        "face03_02_np = np.asarray(face03_02_resized)\n",
        "\n",
        "face03_02_embedding = convert_to_embedding(face03_02_np, model)\n",
        "\n",
        "#face03_02_embedding = ........................"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Zxnx84LHHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60103a8d-27b3-44f4-971e-d88b9f35df91"
      },
      "source": [
        "print(\"L2-norm distance of face02 and face03 = \", np.linalg.norm(face02_embedding - face03_embedding))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-norm distance of face02 and face03 =  13.809298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TMRosurLZAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e454d7a7-a261-4be0-df8a-e274bddfc945"
      },
      "source": [
        "print(\"L2-norm distance of face03 and face03_02 = \", np.linalg.norm(face03_embedding - face03_02_embedding))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2-norm distance of face03 and face03_02 =  6.2999187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8ycn5DVTMsw"
      },
      "source": [
        "#Optional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnRS_JjwTTww"
      },
      "source": [
        "Here is a simple way to get names of files in a directory together with their indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gYUCzcYQJhJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da6f987e-a995-477f-95b5-612f05431676"
      },
      "source": [
        "from os import walk\n",
        "face_dir = '/content/drive/MyDrive/Cher Eng Lim - faces.zip (Unzipped Files)/faces'\n",
        "(_, _, filenames) = next(os.walk(face_dir))\n",
        "\n",
        "for i, name in zip(range(len(filenames)), filenames):\n",
        "  print(i)\n",
        "  print(name)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "face03_02.PNG\n",
            "1\n",
            "face02.PNG\n",
            "2\n",
            "face01.PNG\n",
            "3\n",
            "face03.PNG\n",
            "4\n",
            "face04.PNG\n",
            "5\n",
            "face05.PNG\n",
            "6\n",
            "face06.PNG\n",
            "7\n",
            "face07.PNG\n",
            "8\n",
            "face08.PNG\n",
            "9\n",
            "face09.PNG\n",
            "10\n",
            "face09_02.PNG\n",
            "11\n",
            "face10.PNG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwj1G7TjTc2-"
      },
      "source": [
        "Let's wrtite a simple code to read each file, calculate its embeddings and store the result into a matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeuNBMfqRG24"
      },
      "source": [
        "embedding_matrix = np.empty((len(filenames), 128))\n",
        "\n",
        "for i, name in zip(range(len(filenames)), filenames):\n",
        "  \n",
        "  face = Image.open(name).convert(\"RGB\")\n",
        "\n",
        "  face_resized = face.resize(required_size)\n",
        "\n",
        "  face_np = np.asarray(face_resized)\n",
        "\n",
        "  embedding_matrix[i, :] = convert_to_embedding(face_np, model)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7MnrhadSLBE"
      },
      "source": [
        "Calcualte the pairwise distance of the resultant matrix.\n",
        "\n",
        "Reference: https://jbencook.com/pairwise-distance-in-numpy/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUatUGL-SFM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72721775-fd1c-467e-f681-7622fd99e8ac"
      },
      "source": [
        "from scipy.spatial import distance_matrix\n",
        "\n",
        "result = distance_matrix(embedding_matrix, embedding_matrix)\n",
        "\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.printoptions.html\n",
        "# suppress = True --> use scientfic notation for small numbers\n",
        "with np.printoptions(precision = 2, suppress = True): \n",
        "    print(result)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.   13.8  13.44  6.3  15.91 14.35 14.87 14.95 15.81 13.73 13.91 15.25]\n",
            " [13.8   0.   13.25 13.81 11.45 14.8  15.3  16.42 12.92 13.1  11.96 14.55]\n",
            " [13.44 13.25  0.   14.61 15.5  14.21 14.83 15.15 15.46 14.27 14.07 14.87]\n",
            " [ 6.3  13.81 14.61  0.   15.9  15.49 15.47 15.67 15.97 13.82 14.07 15.01]\n",
            " [15.91 11.45 15.5  15.9   0.   15.51 15.92 15.92 14.41 15.27 14.38 16.28]\n",
            " [14.35 14.8  14.21 15.49 15.51  0.   14.75 13.76 15.46 16.13 14.71 14.81]\n",
            " [14.87 15.3  14.83 15.47 15.92 14.75  0.   14.48 17.23 13.79 14.97 17.01]\n",
            " [14.95 16.42 15.15 15.67 15.92 13.76 14.48  0.   15.56 16.03 15.31 14.55]\n",
            " [15.81 12.92 15.46 15.97 14.41 15.46 17.23 15.56  0.   13.95 13.74 13.97]\n",
            " [13.73 13.1  14.27 13.82 15.27 16.13 13.79 16.03 13.95  0.    7.91 15.33]\n",
            " [13.91 11.96 14.07 14.07 14.38 14.71 14.97 15.31 13.74  7.91  0.   14.98]\n",
            " [15.25 14.55 14.87 15.01 16.28 14.81 17.01 14.55 13.97 15.33 14.98  0.  ]]\n"
          ]
        }
      ]
    }
  ]
}